{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "655fb85c-0df3-4bc8-a837-11cdc5eac4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8aac231-8148-4c1f-b971-a27c4133e852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 331 entries, 0 to 330\n",
      "Data columns (total 42 columns):\n",
      " #   Column                Non-Null Count  Dtype         \n",
      "---  ------                --------------  -----         \n",
      " 0   Patient_ID            331 non-null    int64         \n",
      " 1   Dx_Year               331 non-null    int64         \n",
      " 2   Age                   331 non-null    int64         \n",
      " 3   Sex                   331 non-null    int64         \n",
      " 4   BMI                   327 non-null    float64       \n",
      " 5   ECOG                  314 non-null    Int8          \n",
      " 6   Tumor_Location        331 non-null    int64         \n",
      " 7   Tumor_Location_Group  331 non-null    int64         \n",
      " 8   pT_Stage              331 non-null    category      \n",
      " 9   pN_Stage              331 non-null    category      \n",
      " 10  AJCC_Substage         331 non-null    category      \n",
      " 11  LN_Total              331 non-null    int64         \n",
      " 12  LN_Positive           331 non-null    int64         \n",
      " 13  LNR                   331 non-null    object        \n",
      " 14  Histology             331 non-null    int64         \n",
      " 15  Differentiation       331 non-null    int64         \n",
      " 16  LVI                   327 non-null    float64       \n",
      " 17  PNI                   328 non-null    float64       \n",
      " 18  Tumor_Deposits        331 non-null    int64         \n",
      " 19  Mucinous_Gt_50        331 non-null    int64         \n",
      " 20  Mucinous_Any          331 non-null    int64         \n",
      " 21  Signet_Ring           331 non-null    int64         \n",
      " 22  MSI_Status            329 non-null    category      \n",
      " 23  Tumor_Size_cm         329 non-null    float64       \n",
      " 24  CEA_PreOp             250 non-null    float64       \n",
      " 25  Log_CEA_PreOp         250 non-null    float64       \n",
      " 26  Radical_Op_Date       331 non-null    datetime64[ns]\n",
      " 27  Op_Procedure          331 non-null    category      \n",
      " 28  PreOp_Albumin         278 non-null    float64       \n",
      " 29  Last_FU_Date          331 non-null    datetime64[ns]\n",
      " 30  Recurrence            331 non-null    int64         \n",
      " 31  Recurrence_Date       89 non-null     datetime64[ns]\n",
      " 32  Recurrence_Type       89 non-null     category      \n",
      " 33  Death                 331 non-null    int64         \n",
      " 34  Death_Cause           331 non-null    int64         \n",
      " 35  DFS_Months            329 non-null    float64       \n",
      " 36  OS_Months             329 non-null    float64       \n",
      " 37  Visiting_Staff        331 non-null    int64         \n",
      " 38  Op_Year               331 non-null    int32         \n",
      " 39  time_to_recurrence    89 non-null     float64       \n",
      " 40  edr_18m               331 non-null    Int8          \n",
      " 41  edr_24m               331 non-null    Int8          \n",
      "dtypes: Int8(3), category(6), datetime64[ns](3), float64(10), int32(1), int64(18), object(1)\n",
      "memory usage: 89.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('/Users/huangshifeng/Desktop/stage_III_colon_surv/data/prepare_ML.parquet')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c40eb6-a099-4743-85a3-b17f4c0d028b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Follow-up Analysis ===\n",
      "Median FU: 40.2 months\n",
      "Range: 0.8 - 88.0 months\n",
      "\n",
      "FU adequacy for 18m window:\n",
      "  >18 months: 293 / 331 (88.5%)\n",
      "  <=18 months: 38 (需進一步檢查)\n",
      "\n",
      "追蹤時間<=18個月的病歷號： [5, 10, 12, 26, 28, 31, 32, 39, 46, 67, 69, 76, 80, 81, 83, 90, 96, 117, 119, 128, 130, 137, 139, 148, 154, 158, 178, 201, 217, 223, 238, 257, 275, 285, 295, 301, 304, 311]\n",
      "\n",
      "這些病歷號要手動確認為何追蹤時間這麼短： []\n"
     ]
    }
   ],
   "source": [
    "#檢查FU時間夠不夠\n",
    "df['Follow_Up_Time'] = round((((df['Last_FU_Date'] - df['Radical_Op_Date']).dt.days)/30), 1)\n",
    "df['Follow_Up_Time'].head()\n",
    "\n",
    "print(\"\\n=== Follow-up Analysis ===\")\n",
    "print(f\"Median FU: {df['Follow_Up_Time'].median():.1f} months\")\n",
    "print(f\"Range: {df['Follow_Up_Time'].min():.1f} - {df['Follow_Up_Time'].max():.1f} months\")\n",
    "print(f\"\\nFU adequacy for 18m window:\")\n",
    "print(\n",
    "    f\"  >18 months: {(df['Follow_Up_Time']>18).sum()} / {len(df)} \"\n",
    "    f\"({((df['Follow_Up_Time']>18).mean()*100):.1f}%)\"\n",
    ")\n",
    "print(f\"  <=18 months: {(df['Follow_Up_Time']<=18).sum()} (需進一步檢查)\")\n",
    "\n",
    "df_short_fu = df[df['Follow_Up_Time']<=18]\n",
    "ids = df_short_fu['Patient_ID'].to_list()\n",
    "print(\"\")\n",
    "print(\"追蹤時間<=18個月的病歷號：\", ids)\n",
    "\n",
    "\n",
    "#去掉那些沒復發也沒死的\n",
    "df_short_fu.head()\n",
    "df_no_events = df_short_fu[(df_short_fu['Death'] == 0) & (df_short_fu['Recurrence'] == 0)]\n",
    "ids_for_confirm = df_no_events['Patient_ID'].to_list()\n",
    "print()\n",
    "print(\"這些病歷號要手動確認為何追蹤時間這麼短：\", ids_for_confirm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6700cb2-1661-4533-bc3c-e36ed94d1f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【BASIC INFO】\n",
      "Total rows: 331\n",
      "Total columns: 43\n"
     ]
    }
   ],
   "source": [
    "#Dataset基本資訊\n",
    "print(\"\\n【BASIC INFO】\")\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Total columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ce1cf7-091e-4639-b588-cf9ec7b7aacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【TARGET VARIABLE CHECK-EDR-18m】\n",
      "✓ Target variable found: edr_18m\n",
      "  Data type: Int8\n",
      "  Value counts:\n",
      "{np.int8(0): 269, np.int8(1): 62}\n",
      "  Event rate: 18.7%\n",
      "  Events: 62\n",
      "  ✓ Binary values only: [np.int8(0), np.int8(1)]\n",
      "\n",
      "\n",
      "【TARGET VARIABLE CHECK-EDR-24m】\n",
      "✓ Target variable found: edr_24m\n",
      "  Data type: Int8\n",
      "  Value counts:\n",
      "{np.int8(0): 263, np.int8(1): 68}\n",
      "  Event rate: 20.5%\n",
      "  Events: 68\n",
      "  ✓ Binary values only: [np.int8(0), np.int8(1)]\n"
     ]
    }
   ],
   "source": [
    "#Outcomes變數檢查\n",
    "print(\"\\n【TARGET VARIABLE CHECK-EDR-18m】\")\n",
    "\n",
    "# 檢查EDR-18m\n",
    "if 'edr_18m' in df.columns:\n",
    "    print(f\"✓ Target variable found: edr_18m\")\n",
    "    print(f\"  Data type: {df['edr_18m'].dtype}\")\n",
    "    print(f\"  Value counts:\")\n",
    "    print(df['edr_18m'].value_counts().to_dict())\n",
    "    print(f\"  Event rate: {df['edr_18m'].mean()*100:.1f}%\")\n",
    "    print(f\"  Events: {df['edr_18m'].sum()}\")\n",
    "    \n",
    "    # 檢查是否只有0和1\n",
    "    unique_vals = df['edr_18m'].unique()\n",
    "    if set(unique_vals).issubset({0, 1}):\n",
    "        print(f\"  ✓ Binary values only: {sorted(unique_vals)}\")\n",
    "    else:\n",
    "        print(f\"  ✗ WARNING: Non-binary values found: {unique_vals}\")\n",
    "else:\n",
    "    print(\"✗ ERROR: 'edr_18m' not found!\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "print()\n",
    "print(\"\\n【TARGET VARIABLE CHECK-EDR-24m】\")\n",
    "# 順便一起檢查EDR-24m\n",
    "if 'edr_24m' in df.columns:\n",
    "    print(f\"✓ Target variable found: edr_24m\")\n",
    "    print(f\"  Data type: {df['edr_24m'].dtype}\")\n",
    "    print(f\"  Value counts:\")\n",
    "    print(df['edr_24m'].value_counts().to_dict())\n",
    "    print(f\"  Event rate: {df['edr_24m'].mean()*100:.1f}%\")\n",
    "    print(f\"  Events: {df['edr_24m'].sum()}\")\n",
    "    \n",
    "    # 檢查是否只有0和1\n",
    "    unique_vals = df['edr_24m'].unique()\n",
    "    if set(unique_vals).issubset({0, 1}):\n",
    "        print(f\"  ✓ Binary values only: {sorted(unique_vals)}\")\n",
    "    else:\n",
    "        print(f\"  ✗ WARNING: Non-binary values found: {unique_vals}\")\n",
    "else:\n",
    "    print(\"✗ ERROR: 'edr_24m' not found!\")\n",
    "    print(f\"Available columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39c5f5b1-dfb2-4af1-9caf-b3143a3b2b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【TRAIN/TEST SPLIT CHECK 拆分組檢查】\n",
      "Year distribution:\n",
      "  2017:  44 cases (11 events,  25.0%)\n",
      "  2018:  60 cases (10 events,  16.7%)\n",
      "  2019:  75 cases (15 events,  20.0%)\n",
      "  2020:  74 cases (13 events,  17.6%)\n",
      "  2021:  78 cases (13 events,  16.7%)\n",
      "\n",
      "Suggested split:\n",
      "  Training (2017-2020): 253 cases, 49 events\n",
      "  Testing (2021):        78 cases, 13 events\n",
      "\n",
      "  Events-per-variable (EPV) in training:\n",
      "    10 features: EPV = 4.9 ⚠️\n",
      "    12 features: EPV = 4.1 ⚠️\n",
      "    15 features: EPV = 3.3 ⚠️\n",
      "    20 features: EPV = 2.5 ⚠️\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n【TRAIN/TEST SPLIT CHECK 拆分組檢查】\")\n",
    "\n",
    "if 'Op_Year' in df.columns:\n",
    "    print(\"Year distribution:\")\n",
    "    year_dist = df['Op_Year'].value_counts().sort_index()\n",
    "    for year, count in year_dist.items():\n",
    "        events = df[df['Op_Year']==year]['edr_18m'].sum()\n",
    "        print(f\"  {year}: {count:3d} cases ({events:2d} events, {events/count*100:5.1f}%)\")\n",
    "    \n",
    "    # 建議的split\n",
    "    train = df[df['Op_Year'].between(2017, 2020)]\n",
    "    test = df[df['Op_Year'] == 2021]\n",
    "    \n",
    "    print(f\"\\nSuggested split:\")\n",
    "    print(f\"  Training (2017-2020): {len(train):3d} cases, {train['edr_18m'].sum():2d} events\")\n",
    "    print(f\"  Testing (2021):       {len(test):3d} cases, {test['edr_18m'].sum():2d} events\")\n",
    "    \n",
    "    # Events per variable check\n",
    "    train_events = train['edr_18m'].sum()\n",
    "    print(f\"\\n  Events-per-variable (EPV) in training:\")\n",
    "    for n_features in [10, 12, 15, 20]:\n",
    "        epv = train_events / n_features\n",
    "        status = \"✓\" if epv >= 5 else \"⚠️\"\n",
    "        print(f\"    {n_features} features: EPV = {epv:.1f} {status}\")\n",
    "else:\n",
    "    print(\"✗ ERROR: 'Op_Year' not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcf9c42-34b2-4fef-8d31-f4b9ad8bf0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【MISSING VALUES CHECK 缺失值檢查】\n",
      "⚠️ Found 14 columns with missing values:\n",
      "                    Missing_Count  Missing_Pct\n",
      "Recurrence_Date               242        73.11\n",
      "Recurrence_Type               242        73.11\n",
      "time_to_recurrence            242        73.11\n",
      "CEA_PreOp                      81        24.47\n",
      "Log_CEA_PreOp                  81        24.47\n",
      "PreOp_Albumin                  53        16.01\n",
      "ECOG                           17         5.14\n",
      "BMI                             4         1.21\n",
      "LVI                             4         1.21\n",
      "PNI                             3         0.91\n",
      "MSI_Status                      2         0.60\n",
      "Tumor_Size_cm                   2         0.60\n",
      "DFS_Months                      2         0.60\n",
      "OS_Months                       2         0.60\n",
      "\n",
      "⚠️ HIGH MISSING (>20%):\n",
      "                    Missing_Count  Missing_Pct\n",
      "Recurrence_Date               242        73.11\n",
      "Recurrence_Type               242        73.11\n",
      "time_to_recurrence            242        73.11\n",
      "CEA_PreOp                      81        24.47\n",
      "Log_CEA_PreOp                  81        24.47\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n【MISSING VALUES CHECK 缺失值檢查】\")\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing,\n",
    "    'Missing_Pct': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Pct', ascending=False)\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"⚠️ Found {len(missing_df)} columns with missing values:\")\n",
    "    print(missing_df.head(20).to_string())\n",
    "    \n",
    "    # 高缺失率變數\n",
    "    high_missing = missing_df[missing_df['Missing_Pct'] > 20]\n",
    "    if len(high_missing) > 0:\n",
    "        print(f\"\\n⚠️ HIGH MISSING (>20%):\")\n",
    "        print(high_missing.to_string())\n",
    "else:\n",
    "    print(\"✓ No missing values found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4795b9bc-393e-4e5b-a385-b680f3c7bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【DATA TYPES CHECK 資料型態檢查】\n",
      "Data type distribution:\n",
      "  int64: 17 columns\n",
      "  float64: 12 columns\n",
      "  Int8: 4 columns\n",
      "  datetime64[ns]: 3 columns\n",
      "  category: 1 columns\n",
      "  category: 1 columns\n",
      "  category: 1 columns\n",
      "  category: 1 columns\n",
      "  category: 1 columns\n",
      "  category: 1 columns\n",
      "  int32: 1 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n【DATA TYPES CHECK 資料型態檢查】\")\n",
    "\n",
    "dtypes_summary = df.dtypes.value_counts()\n",
    "print(\"Data type distribution:\")\n",
    "for dtype, count in dtypes_summary.items():\n",
    "    print(f\"  {dtype}: {count} columns\")\n",
    "\n",
    "# 檢查object型態（可能需要編碼）\n",
    "object_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if len(object_cols) > 0:\n",
    "    print(f\"\\n⚠️ Object columns found (may need encoding): {len(object_cols)}\")\n",
    "    for col in object_cols[:10]:  # 只顯示前10個\n",
    "        unique = df[col].nunique()\n",
    "        print(f\"  {col}: {unique} unique values\")\n",
    "        if unique <= 10:\n",
    "            print(f\"    → {df[col].value_counts().head(5).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d645f0b8-3576-4245-a51b-2cc8d86f6025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Patient_ID                       int64\n",
       "Dx_Year                          int64\n",
       "Age                              int64\n",
       "Sex                              int64\n",
       "BMI                            float64\n",
       "ECOG                              Int8\n",
       "Tumor_Location                   int64\n",
       "Tumor_Location_Group             int64\n",
       "pT_Stage                      category\n",
       "pN_Stage                      category\n",
       "AJCC_Substage                 category\n",
       "LN_Total                         int64\n",
       "LN_Positive                      int64\n",
       "LNR                            float64\n",
       "Histology                        int64\n",
       "Differentiation                  int64\n",
       "LVI                            float64\n",
       "PNI                            float64\n",
       "Tumor_Deposits                   int64\n",
       "Mucinous_Gt_50                   int64\n",
       "Mucinous_Any                     int64\n",
       "Signet_Ring                      int64\n",
       "MSI_Status                    category\n",
       "Tumor_Size_cm                  float64\n",
       "CEA_PreOp                      float64\n",
       "Log_CEA_PreOp                  float64\n",
       "Radical_Op_Date         datetime64[ns]\n",
       "Op_Procedure                  category\n",
       "PreOp_Albumin                  float64\n",
       "Last_FU_Date            datetime64[ns]\n",
       "Recurrence                       int64\n",
       "Recurrence_Date         datetime64[ns]\n",
       "Recurrence_Type               category\n",
       "Death                            int64\n",
       "Death_Cause                      int64\n",
       "DFS_Months                     float64\n",
       "OS_Months                      float64\n",
       "Visiting_Staff                   int64\n",
       "Op_Year                          int32\n",
       "time_to_recurrence             float64\n",
       "edr_18m                           Int8\n",
       "edr_24m                           Int8\n",
       "Follow_Up_Time                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#上個步驟LNR的dtype看起來有問題，立馬處理\n",
    "\n",
    "df['LNR_clean'] = df['LNR'].str.strip().str.lower()\n",
    "df['LNR_clean'] = df['LNR_clean'].str.replace(\"%\", \"\")\n",
    "df['LNR'] = round(df['LNR_clean'].astype(float)/100, 3)\n",
    "df['LNR'].head()\n",
    "df = df.drop(columns=\"LNR_clean\")\n",
    "\n",
    "#重新確認一次\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13423f23-d18a-4781-972a-276e1e2bd824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.706\n",
       "1    0.059\n",
       "2    0.000\n",
       "3    0.176\n",
       "4    0.167\n",
       "Name: LNR, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LNR'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7e53cf0-9f42-4066-9479-0db46a6441c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【CATEGORICAL FEATURES CHECK 類別變數檢查】\n",
      "\n",
      "  AJCC_Substage:\n",
      "    Unique values: 3\n",
      "    Distribution: {'3B': 227, '3C': 67, '3A': 37}\n",
      "\n",
      "  Differentiation:\n",
      "    Unique values: 5\n",
      "    Distribution: {2: 299, 3: 23, 4: 5, 1: 3, 9: 1}\n",
      "    ⚠️ Rare categories (<1%): [1, 9]\n",
      "\n",
      "  Tumor_Location:\n",
      "    Unique values: 8\n",
      "    Distribution: {7: 133, 2: 64, 8: 64, 1: 21, 4: 20, 6: 19, 3: 7, 5: 3}\n",
      "    ⚠️ Rare categories (<1%): [5]\n",
      "\n",
      "  LVI:\n",
      "    Unique values: 2\n",
      "    Distribution: {1.0: 167, 0.0: 160}\n",
      "\n",
      "  PNI:\n",
      "    Unique values: 2\n",
      "    Distribution: {0.0: 274, 1.0: 54}\n",
      "\n",
      "  Tumor_Deposits:\n",
      "    Unique values: 2\n",
      "    Distribution: {0: 314, 1: 17}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n【CATEGORICAL FEATURES CHECK 類別變數檢查】\")\n",
    "\n",
    "categorical_candidates = ['AJCC_Substage', 'pT', 'pN', 'Differentiation', \n",
    "                         'Tumor_Location', 'LVI', 'PNI', 'Tumor_Deposits']\n",
    "\n",
    "for col in categorical_candidates:\n",
    "    if col in df.columns:\n",
    "        n_unique = df[col].nunique()\n",
    "        print(f\"\\n  {col}:\")\n",
    "        print(f\"    Unique values: {n_unique}\")\n",
    "        if n_unique <= 20:\n",
    "            vc = df[col].value_counts()\n",
    "            print(f\"    Distribution: {vc.to_dict()}\")\n",
    "            \n",
    "            # 檢查稀有類別\n",
    "            rare = vc[vc < len(df) * 0.01]  # <1%的類別\n",
    "            if len(rare) > 0:\n",
    "                print(f\"    ⚠️ Rare categories (<1%): {rare.index.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bce6351-98f3-4ee8-ad49-f4193e9305d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#處理一下Differentiation\n",
    "df['Differentiation'] = df['Differentiation'].replace(9, np.nan).astype(\"Int8\")\n",
    "df['Differentiation'].value_counts()\n",
    "df['Differentiation'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "af35513d-c30e-4b51-8221-982363e358ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "【9. DUPLICATE CHECK】\n",
      "✓ No duplicate rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n【9. DUPLICATE CHECK】\")\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "if duplicates > 0:\n",
    "    print(f\"⚠️ WARNING: Found {duplicates} duplicate rows\")\n",
    "else:\n",
    "    print(\"✓ No duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6e45095-b2b7-4c26-bd28-0a95dfd1f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#拆分訓練級和驗證集\n",
    "train = df[df['Op_Year'].between(2017, 2020)].copy()\n",
    "test = df[df['Op_Year'] == 2021].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "709f6043-3287-43a9-99e8-c991848ec2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_parquet('/Users/huangshifeng/Desktop/stage_III_colon_surv/data/train.parquet')\n",
    "test.to_parquet('/Users/huangshifeng/Desktop/stage_III_colon_surv/data/test.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
